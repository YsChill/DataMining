# -*- coding: utf-8 -*-
"""SupportVectorMachinesW25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zgVmY_S1xw3ILrxGBusHw39KzsTwLGwv
"""

from sklearn import svm
import pandas as pd
import numpy as np

C=1e+03 #1000
gamma=1e-05 #0.0001
clf = svm.SVC(C=C, gamma=gamma, kernel='rbf', probability=True)

import pandas as pd
train = pd.read_csv('./diabetes_train.csv') #this is our dataset, please change the path for your case
test = pd.read_csv('./diabetes_test.csv')
train.columns[:8] #wanted to show which attributs we have

clf = clf.fit(train.iloc[:,0:8], train.iloc[:,8]) #first paramater data, second labels
y_pred = clf.predict(test.iloc[:,0:8]) #doing prediction on unknown test set
y_pred

from sklearn.metrics import confusion_matrix #let's see how good we did
y_true = test.iloc[:,8]
tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
tn, fp, fn, tp

#clf = svm.SVC(C=C, gamma=gamma, kernel='rbf', probability=True)
C = [0.1, 1, 10, 100, 1e+03, 1e+04, 1e+05]
gamma = [1e-03, 1e-04, 1e-05, 1e-06]
degrees = [1, 2]
results = []

for c in C:
    for d in degrees:
        for g in gamma:
            if d >= 2 and c >= 1000:
               results.append({
                    'Kernel': 'None',
                    'C': "0",
                    'Gamma': "0",
                    'Degree': "0",
                    'Train Accuracy': "0",
                    'Test Accuracy': "0"
                })
            else:
                clf = svm.SVC(C=c, gamma=g, kernel='poly', degree=d, probability=True)
                clf.fit(train.iloc[:, 0:8], train.iloc[:, 8])
                y_pred = clf.predict(test.iloc[:, 0:8])
                tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

                from sklearn.metrics import accuracy_score

                test_acc = (tp + tn) / (tp + tn + fp + fn)
                y_pred_train = clf.predict(train.iloc[:, 0:8])
                train_acc = accuracy_score(train.iloc[:, 8], y_pred_train)

                print(f"Kernel = Poly, C={c}, Degree={d}, Gamma={g} | Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")
                results.append({
                    'Kernel': 'Poly',
                    'C': c,
                    'Gamma': g,
                    'Degree': d,
                    'Train Accuracy': train_acc,
                    'Test Accuracy': test_acc
                })

for c in C:
  for g in gamma:
    clf = svm.SVC(C=c, gamma=g, kernel='sigmoid', probability=True)
    clf.fit(train.iloc[:,0:8], train.iloc[:,8])
    y_pred = clf.predict(test.iloc[:,0:8])
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

    from sklearn.metrics import accuracy_score

    test_acc = (tp + tn) / (tp + tn + fp + fn)

    y_pred_train = clf.predict(train.iloc[:, 0:8])
    train_acc = accuracy_score(train.iloc[:, 8], y_pred_train)

    print(f"Kernal = Sigmoid, C={c}, gamma={g} | Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")
    results.append({
            'Kernel': 'Sigmoid',
            'C': c,
            'Gamma': g,
            'Degree': None,
            'Train Accuracy': train_acc,
            'Test Accuracy': test_acc
        })

for c in C:
  for g in gamma:
    clf = svm.SVC(C=c, gamma=g, kernel='rbf', probability=True)
    clf.fit(train.iloc[:,0:8], train.iloc[:,8])
    y_pred = clf.predict(test.iloc[:,0:8])
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

    from sklearn.metrics import accuracy_score

    test_acc = (tp + tn) / (tp + tn + fp + fn)

    y_pred_train = clf.predict(train.iloc[:, 0:8])
    train_acc = accuracy_score(train.iloc[:, 8], y_pred_train)

    print(f"Kernal = RBF, C={c}, gamma={g} | Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")
    results.append({
            'Kernel': 'RBF',
            'C': c,
            'Gamma': g,
            'Degree': None,
            'Train Accuracy': train_acc,
            'Test Accuracy': test_acc
        })

C = [0.1, 1, 10, 100, 1e+03]

for c in C:
  clf = svm.SVC(C=c, kernel='linear', probability=True)  # gamma is ignored
  clf.fit(train.iloc[:, 0:8], train.iloc[:, 8])
  y_pred = clf.predict(test.iloc[:, 0:8])
  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

  from sklearn.metrics import accuracy_score

  test_acc = (tp + tn) / (tp + tn + fp + fn)

  y_pred_train = clf.predict(train.iloc[:, 0:8])
  train_acc = accuracy_score(train.iloc[:, 8], y_pred_train)

  print(f"Kernel = Linear, C={c} | Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")
  results.append({
        'Kernel': 'Linear',
        'C': c,
        'Gamma': None,
        'Degree': None,
        'Train Accuracy': train_acc,
        'Test Accuracy': test_acc
    })

results_df = pd.DataFrame(results)
results_df.to_csv('svm_results.csv', index=False)
print("Results exported to svm_results.csv")

import numpy as np
from sklearn.metrics import roc_curve, auc
from numpy import interp

y = test.iloc[:,8]
scores = clf.predict_proba(test.iloc[:,0:8])
scores[:,1]
#y is the true labels, scores[:,1] which has probabilities
fpr, tpr, thresholds = roc_curve(y, scores[:,1], pos_label='tested_positive')
#fpr, tpr, thresholds = roc_curve(true_labels, scores[:,1], pos_label=1)

roc_auc = auc(fpr,tpr)

print(fpr)

print(tpr)

print(thresholds)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()